{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "sy49gSlH_at8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_breast_cancer # data from sk learn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load the data from lib\n",
        "\n",
        "cancer = load_breast_cancer()\n",
        "# creat x and y\n",
        "x = cancer.data\n",
        "y = cancer.target\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XyvdZlGo_kDf",
        "outputId": "a082eae2-e536-4611-8eec-ca7a9fa9143a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
              "       'mean smoothness', 'mean compactness', 'mean concavity',\n",
              "       'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
              "       'radius error', 'texture error', 'perimeter error', 'area error',\n",
              "       'smoothness error', 'compactness error', 'concavity error',\n",
              "       'concave points error', 'symmetry error',\n",
              "       'fractal dimension error', 'worst radius', 'worst texture',\n",
              "       'worst perimeter', 'worst area', 'worst smoothness',\n",
              "       'worst compactness', 'worst concavity', 'worst concave points',\n",
              "       'worst symmetry', 'worst fractal dimension'], dtype='<U23')"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# add the bias \"ones\"\n",
        "x = np.hstack([np.ones((x.shape[0], 1)), x])"
      ],
      "metadata": {
        "id": "RF5LzyRRATQ7"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make is as a data frame \"pandas\"\n",
        "\n",
        "columns = [\"bias\"] + cancer.feature_names.tolist()\n",
        "df = pd.DataFrame(x, columns=columns)\n",
        "df['target'] = y\n",
        "\n",
        "print(df.head)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AU9fm2P-Ae4K",
        "outputId": "4527b3a2-7f80-43b1-d745-65f3d87530b9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<bound method NDFrame.head of      bias  mean radius  mean texture  mean perimeter  mean area  \\\n",
            "0     1.0        17.99         10.38          122.80     1001.0   \n",
            "1     1.0        20.57         17.77          132.90     1326.0   \n",
            "2     1.0        19.69         21.25          130.00     1203.0   \n",
            "3     1.0        11.42         20.38           77.58      386.1   \n",
            "4     1.0        20.29         14.34          135.10     1297.0   \n",
            "..    ...          ...           ...             ...        ...   \n",
            "564   1.0        21.56         22.39          142.00     1479.0   \n",
            "565   1.0        20.13         28.25          131.20     1261.0   \n",
            "566   1.0        16.60         28.08          108.30      858.1   \n",
            "567   1.0        20.60         29.33          140.10     1265.0   \n",
            "568   1.0         7.76         24.54           47.92      181.0   \n",
            "\n",
            "     mean smoothness  mean compactness  mean concavity  mean concave points  \\\n",
            "0            0.11840           0.27760         0.30010              0.14710   \n",
            "1            0.08474           0.07864         0.08690              0.07017   \n",
            "2            0.10960           0.15990         0.19740              0.12790   \n",
            "3            0.14250           0.28390         0.24140              0.10520   \n",
            "4            0.10030           0.13280         0.19800              0.10430   \n",
            "..               ...               ...             ...                  ...   \n",
            "564          0.11100           0.11590         0.24390              0.13890   \n",
            "565          0.09780           0.10340         0.14400              0.09791   \n",
            "566          0.08455           0.10230         0.09251              0.05302   \n",
            "567          0.11780           0.27700         0.35140              0.15200   \n",
            "568          0.05263           0.04362         0.00000              0.00000   \n",
            "\n",
            "     mean symmetry  ...  worst texture  worst perimeter  worst area  \\\n",
            "0           0.2419  ...          17.33           184.60      2019.0   \n",
            "1           0.1812  ...          23.41           158.80      1956.0   \n",
            "2           0.2069  ...          25.53           152.50      1709.0   \n",
            "3           0.2597  ...          26.50            98.87       567.7   \n",
            "4           0.1809  ...          16.67           152.20      1575.0   \n",
            "..             ...  ...            ...              ...         ...   \n",
            "564         0.1726  ...          26.40           166.10      2027.0   \n",
            "565         0.1752  ...          38.25           155.00      1731.0   \n",
            "566         0.1590  ...          34.12           126.70      1124.0   \n",
            "567         0.2397  ...          39.42           184.60      1821.0   \n",
            "568         0.1587  ...          30.37            59.16       268.6   \n",
            "\n",
            "     worst smoothness  worst compactness  worst concavity  \\\n",
            "0             0.16220            0.66560           0.7119   \n",
            "1             0.12380            0.18660           0.2416   \n",
            "2             0.14440            0.42450           0.4504   \n",
            "3             0.20980            0.86630           0.6869   \n",
            "4             0.13740            0.20500           0.4000   \n",
            "..                ...                ...              ...   \n",
            "564           0.14100            0.21130           0.4107   \n",
            "565           0.11660            0.19220           0.3215   \n",
            "566           0.11390            0.30940           0.3403   \n",
            "567           0.16500            0.86810           0.9387   \n",
            "568           0.08996            0.06444           0.0000   \n",
            "\n",
            "     worst concave points  worst symmetry  worst fractal dimension  target  \n",
            "0                  0.2654          0.4601                  0.11890       0  \n",
            "1                  0.1860          0.2750                  0.08902       0  \n",
            "2                  0.2430          0.3613                  0.08758       0  \n",
            "3                  0.2575          0.6638                  0.17300       0  \n",
            "4                  0.1625          0.2364                  0.07678       0  \n",
            "..                    ...             ...                      ...     ...  \n",
            "564                0.2216          0.2060                  0.07115       0  \n",
            "565                0.1628          0.2572                  0.06637       0  \n",
            "566                0.1418          0.2218                  0.07820       0  \n",
            "567                0.2650          0.4087                  0.12400       0  \n",
            "568                0.0000          0.2871                  0.07039       1  \n",
            "\n",
            "[569 rows x 32 columns]>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# after getting the data ready we split it using sk learn split\n",
        "\n",
        "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=42)"
      ],
      "metadata": {
        "id": "q2DDhxygA7yl"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# logistic reg class from scratch\n",
        "class LogisticRegression:\n",
        "  def __init__(self, learning_rate=0.01, num_iterations=1000):\n",
        "    self.learning_rate = learning_rate\n",
        "    self.num_iterations = num_iterations\n",
        "    self.weights = None\n",
        "\n",
        "# sigmoid fun\n",
        "  def sigmoid (self, z):\n",
        "      return 1/ (1+ np.exp(-z))\n",
        "\n",
        "# fit using gradiant\n",
        "  def fit(self, x, y):\n",
        "    # Initialize weights as zeros\n",
        "    self.weights = np.zeros(x.shape[1])\n",
        "\n",
        "    # Perform gradient descent\n",
        "    for _ in range(self.num_iterations):\n",
        "        # Linear combination of features and weights\n",
        "        z = np.dot(x, self.weights)\n",
        "        # Apply sigmoid function to get predicted probabilities\n",
        "        prediction = self.sigmoid(z)\n",
        "        # Compute gradient of the loss function\n",
        "        gradient = np.dot(x.T, (prediction - y)) / len(y)\n",
        "        # Update weights using the gradient and learning rate\n",
        "        self.weights -= self.learning_rate * gradient\n",
        "# predict fun\n",
        "  def predict(self, x ):\n",
        "    z = np.dot(x,self.weights)\n",
        "    prediction = self.sigmoid(z)\n",
        "    return np.round(prediction)\n"
      ],
      "metadata": {
        "id": "Y34QCI6zBVAs"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# now we create and train the model with class we built\n",
        "\n",
        "model = LogisticRegression()\n",
        "model.fit(x_train,y_train)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uMCalkCRFI4a",
        "outputId": "6f1bf445-81a6-4de3-89b7-321df7722b14"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-00caf1a4ebb5>:10: RuntimeWarning: overflow encountered in exp\n",
            "  return 1/ (1+ np.exp(-z))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# predict on the true \"real\" test set\n",
        "y_pred = model.predict(x_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FImaxXUDGCcp",
        "outputId": "c9cfb38f-6fe9-4362-ca9a-2fa44c8fe50d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-00caf1a4ebb5>:10: RuntimeWarning: overflow encountered in exp\n",
            "  return 1/ (1+ np.exp(-z))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_score  = accuracy_score(y_test,y_pred)\n",
        "print(accuracy_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7YRm2Bv7GNPi",
        "outputId": "01621ecf-e490-4d01-a6c2-724d871be794"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9473684210526315\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**and we can use SKlearn**\n",
        "\n",
        "\"`from sklearn.linear_model import LogisticRegression`\""
      ],
      "metadata": {
        "id": "Yn7_0vFZGivO"
      }
    }
  ]
}